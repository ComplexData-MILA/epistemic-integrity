{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epistemic_verbs = {\n",
    "    \"High Modal Strength\": [\"bet\", \"expect\", \"hope\", \"know\", \"mean\", \"predict\", \"see\", \"trust\"],\n",
    "    \"Medium Modal Strength\": [\"assume\", \"believe\", \"feel\", \"find\", \"guess\", \"imagine\", \"presuppose\", \"presume\", \"reckon\", \"suppose\", \"think\", \"seem\", \"appear\", \"gather\", \"hypothesize\", \"take\", \"understand\"],\n",
    "    \"Low Modal Strength\": [\"doubt\", \"suspect\", \"wonder\"]\n",
    "}\n",
    "\n",
    "epistemic_adjectives = {\n",
    "    \"High Modal Strength\": [\"sure\", \"positive\"],\n",
    "    \"Medium Modal Strength\": [\"likely\", \"probable\"],\n",
    "    \"Low Modal Strength\": [\"doubtful\", \"possible\", \"uncertain\", \"unclear\", \"unconvinced\", \"unsure\", \"unlikely\", \"improbable\"]\n",
    "}\n",
    "\n",
    "epistemic_nouns = {\n",
    "    \"High Modal Strength\": [\"assertion\", \"belief\", \"conviction\", \"fact\", \"knowledge\"],\n",
    "    \"Medium Modal Strength\": [\"Assumption\", \"chance\", \"claim\", \"hypothesis\", \"idea\", \"impression\", \"feeling\", \"opinion\", \"possibility\", \"suggestion\"],\n",
    "    \"Low Modal Strength\": [\"Doubt\"]\n",
    "}\n",
    "\n",
    "epistemic_adverbs = {\n",
    "    \"High Modal Strength\": [\"actually\", \"assuredly\", \"certainly\", \"clearly\", \"definitely\", \"indubitably\", \"ineluctably\", \"inescapably\", \"manifestly\", \"obviously\", \"really\", \"surely\", \"truly\", \"unarguably\", \"unavoidably\", \"undeniably\", \"undoubtedly\", \"unquestionably\"],\n",
    "    \"Medium Modal Strength\": [\"apparently\", \"kind of\", \"predictably\", \"probably\", \"sort of\", \"supposedly\", \"allegedly\", \"reportedly\", \"evidently\"],\n",
    "    \"Low Modal Strength\": [\"perhaps\", \"possibly\", \"conceivably\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12406\\AppData\\Local\\Temp\\ipykernel_20848\\921009643.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.989091937273428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12406\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\12406\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['adverb_Low Modal Strength', 'verb_High Modal Strength', 'verb_Medium Modal Strength'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = []\n",
    "with open('sentence-level-certainty.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def epistemic_tokenizer(sentence):\n",
    "    tokens = []\n",
    "    for word in sentence.split():\n",
    "        word_lower = word.lower()\n",
    "        for strength, words_list in epistemic_verbs.items():\n",
    "            if word_lower in words_list:\n",
    "                tokens.append(f\"verb_{strength}\")\n",
    "        for strength, words_list in epistemic_adjectives.items():\n",
    "            if word_lower in words_list:\n",
    "                tokens.append(f\"adjective_{strength}\")\n",
    "        for strength, words_list in epistemic_nouns.items():\n",
    "            if word_lower in words_list:\n",
    "                tokens.append(f\"noun_{strength}\")\n",
    "        for strength, words_list in epistemic_adverbs.items():\n",
    "            if word_lower in words_list:\n",
    "                tokens.append(f\"adverb_{strength}\")\n",
    "    return tokens\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=epistemic_tokenizer, lowercase=True, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['finding']).toarray()\n",
    "\n",
    "y = df['sentence-level-certainty'].values.reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_original = scaler.inverse_transform(y_test)\n",
    "y_pred_original = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
