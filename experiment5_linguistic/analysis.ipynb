{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          statement1 classification1   \n",
      "0  An image of empty grocery store shelves shows ...           false  \\\n",
      "1  “Raising the debt limit is paying our old debt...            true   \n",
      "2  People who are vaccinated for the coronavirus ...           false   \n",
      "3  Dr. Anthony Fauci and U.S. health officials pl...           false   \n",
      "4  Says Dr. Anthony Fauci said he will not “take ...           false   \n",
      "\n",
      "                                        explanation1 true certainty1   \n",
      "0  \\n\\nWhile the statement suggests a causal rela...              75  \\\n",
      "1  The statement accurately reflects the purpose ...              90   \n",
      "2  While vaccination significantly reduces the ch...              90   \n",
      "3  The statement seems to make a speculative clai...              10   \n",
      "4  There is no verifiable evidence or credible so...              80   \n",
      "\n",
      "                                          statement2 classification2   \n",
      "0  “Europe COMPLETELY BANS the Moderna vaccine fo...           false  \\\n",
      "1  “The Walker-Kleefisch administration slashed $...           false   \n",
      "2  “Pfizer admits there’s no vaccine approved by ...           false   \n",
      "3  The percentage of vaccinated employees at Unit...            true   \n",
      "4  “U.S. acres burned each year are much fewer no...            true   \n",
      "\n",
      "                                        explanation2 true certainty2   \n",
      "0  This statement is false. While there have been...              90  \\\n",
      "1  While it is possible that the Walker-Kleefisch...              75   \n",
      "2  Pfizer's COVID-19 vaccine (BNT162b2) has been ...              90   \n",
      "3  After the mandate, it is likely that some unva...              95   \n",
      "4  The statement accurately describes the trend o...              90   \n",
      "\n",
      "  prediction truth  \n",
      "0          1     2  \n",
      "1          1     1  \n",
      "2          2     2  \n",
      "3          1     2  \n",
      "4          1     2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load the data from the JSON file\n",
    "with open('LIAR-Evaluated.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def clean_percentage(value):\n",
    "    if isinstance(value, str):\n",
    "        match = re.search(r'\\d+(?:\\.\\d+)?', value)\n",
    "        if match:\n",
    "            return float(match.group())\n",
    "    return 0  # or return None if you prefer\n",
    "\n",
    "# Clean the true certainties\n",
    "df['true certainty1'] = df['true certainty1'].apply(clean_percentage)\n",
    "df['true certainty2'] = df['true certainty2'].apply(clean_percentage)\n",
    "\n",
    "# Calculate the difference in true certainties\n",
    "df['certainty difference'] = abs(df['true certainty1'] - df['true certainty2'])\n",
    "\n",
    "# Calculate whether the prediction was correct\n",
    "df['correct'] = df['prediction'] == df['truth']\n",
    "\n",
    "# Create a new column for the classification status\n",
    "df['classification1'] = df['classification1'].str.lower()\n",
    "df['classification2'] = df['classification2'].str.lower()\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_counts = df['classification1'].value_counts(normalize=True) * 100\n",
    "print(\"Percentage of 'true' classifications in 'classification1':\", classification_counts['true'])\n",
    "\n",
    "classification_counts = df['classification2'].value_counts(normalize=True) * 100\n",
    "print(\"Percentage of 'true' classifications in 'classification2':\", classification_counts['true'])\n",
    "\n",
    "classification_counts = df['classification status'].value_counts(normalize=True) * 100\n",
    "print(\"Percentage of 'One True One False' classifications:\", classification_counts['One True One False'])\n",
    "print(\"Percentage of 'Both True' classifications:\", classification_counts['Both True'])\n",
    "print(\"Percentage of 'Both False' classifications:\", classification_counts['Both False'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['classification status'] = 'One True One False'\n",
    "df.loc[(df['classification1'] == 'true') & (df['classification2'] == 'true'), 'classification status'] = 'Both True'\n",
    "df.loc[(df['classification1'] == 'false') & (df['classification2'] == 'false'), 'classification status'] = 'Both False'\n",
    "\n",
    "# Plot the accuracy by classification status\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = df.groupby('classification status')['correct'].mean().plot(kind='bar')\n",
    "plt.title('Accuracy by Classification Status')\n",
    "plt.xlabel('Classification Status')\n",
    "plt.ylabel('Percentage Correct')\n",
    "\n",
    "# Add the percentage values on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Define bins for the certainty difference\n",
    "bins = [0, 10, 20, df['certainty difference'].max()]\n",
    "labels = ['<10%', '10-20%', '>20%']\n",
    "df['certainty difference bin'] = pd.cut(df['certainty difference'], bins=bins, labels=labels)\n",
    "\n",
    "# Plot the accuracy by certainty difference\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = df.groupby('certainty difference bin')['correct'].mean().plot(kind='bar')\n",
    "plt.title('Accuracy by Certainty Difference')\n",
    "plt.xlabel('Certainty Difference')\n",
    "plt.ylabel('Percentage Correct')\n",
    "\n",
    "# Add the percentage values on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification status\n",
      "Both False            68.316832\n",
      "One True One False    30.693069\n",
      "Both True              0.990099\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "classification_counts = df['classification status'].value_counts(normalize=True) * 100\n",
    "print(classification_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
